{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a008e623-4a2e-4818-a711-638a867fd88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "import openai\n",
    "import re\n",
    "import requests\n",
    "import sys\n",
    "from num2words import num2words\n",
    "import numpy as np\n",
    "from openai.embeddings_utils import get_embedding, cosine_similarity\n",
    "import tiktoken\n",
    "\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\") \n",
    "openai.organization = os.getenv(\"OPENAI_ORGANIZATION\") \n",
    "\n",
    "start_time=time.time()\n",
    "path ='c:\\\\path_to_your_directory_with_files_to_ingest'\n",
    "\n",
    "########### This helps takes care of removing metadata\n",
    "search_string = \"---\" \n",
    "metadata_counter = 0\n",
    "############\n",
    "d = []\n",
    "text=\"\"\n",
    "\n",
    "for root, directories, files in os.walk(path , topdown=False):\n",
    "    for file in files:\n",
    "        if file.lower().endswith(\".md\"):\n",
    "            name =(os.path.join(root,file))\n",
    "            f = open(name, \"r\",encoding=\"utf-8\")\n",
    "            for line in f:\n",
    "                if line.find(search_string) !=-1 and metadata_counter !=2:\n",
    "                    metadata_counter+=1\n",
    "                if line.find(search_string) != 0 and metadata_counter==2:\n",
    "                    text +=line\n",
    "            f.close()\n",
    "            d.append({'FILE NAME': file ,'CONTENT': text})\n",
    "            pd.DataFrame(d)\n",
    "            metadata_counter = 0\n",
    "            text=\"\"\n",
    "end_time = time.time()\n",
    "duration = end_time - start_time\n",
    "\n",
    "print (\"Script Execution: \", duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a771194f-f5bb-423e-a75e-ed0873313e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(d)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efca7fd2-d9d4-4422-b133-4803c5769772",
   "metadata": {},
   "outputs": [],
   "source": [
    "# s is input text\n",
    "def normalize_text(s, sep_token = \" \\n \"):\n",
    "    s = re.sub(r'\\s+',  ' ', s).strip()\n",
    "    s = re.sub(r\". ,\",\"\",s)\n",
    "    # remove all instances of multiple spaces\n",
    "    s = s.replace(\"..\",\".\")\n",
    "    s = s.replace(\". .\",\".\")\n",
    "    s = s.replace(\"\\n\", \"\")\n",
    "    s = s.replace(\"#\",\"\")\n",
    "    s = s.strip()\n",
    "    \n",
    "    return s\n",
    "\n",
    "df['CONTENT'] = df[\"CONTENT\"].apply(lambda x : normalize_text(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96b2508b-4b0c-417e-b3ff-0bb4ef738dd2",
   "metadata": {},
   "source": [
    "| GENERATION |TOKENIZER    | MAX INPUT TOKENS| KNOWLEDGE CUTOFF|\n",
    "|------------|-------------|-----------------|-----------------|\n",
    "| V2         | cl100k_base | 8191            | Sep 2021        |\n",
    "| V1         | GPT-2/GPT-3 | 2046            | Aug 2020        |\n",
    "\n",
    "\n",
    "https://beta.openai.com/docs/guides/embeddings/what-are-embeddings\n",
    "\n",
    "https://openai.com/blog/new-and-improved-embedding-model/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe07d0a-ce24-4210-b1ce-a50faed184b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tiktoken.get_encoding(\"cl100k_base\")\n",
    "df['n_tokens'] = df[\"CONTENT\"].apply(lambda x: len(tokenizer.encode(x)))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b3f794-d584-4565-8ef5-86e127aed559",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on https://openai.com/api/pricing/ on 01/29/2023\n",
    "# If you were using this for approximating pricing with Azure OpenAI adjust the values below with: https://azure.microsoft.com/pricing/details/cognitive-services/openai-service/\n",
    "\n",
    "#MODEL\tUSAGE\n",
    "#Ada     v1\t$0.0040 / 1K tokens\n",
    "#Babbage v1\t$0.0050 / 1K tokens\n",
    "#Curie   v1\t$0.0200 / 1K tokens\n",
    "#Davinci v1\t$0.2000 / 1K tokens\n",
    "\n",
    "#MODEL\tUSAGE\n",
    "#Ada     v2\t$0.0004 / 1K tokens\n",
    "#This Ada model, text-embedding-ada-002, is a better and lower cost replacement for our older embedding models. \n",
    "\n",
    "n_tokens_sum = df['n_tokens'].sum()\n",
    "\n",
    "ada_v1_embeddings_cost = (n_tokens_sum/1000) *.0040\n",
    "babbage_v1_embeddings_cost = (n_tokens_sum/1000) *.0050\n",
    "curie_v1_embeddings_cost = (n_tokens_sum/1000) *.02\n",
    "davinci_v1_embeddings_cost = (n_tokens_sum/1000) *.2\n",
    "\n",
    "ada_v2_embeddings_cost = (n_tokens_sum/1000) *.0004\n",
    "\n",
    "print(\"Number of tokens: \" + str(n_tokens_sum) + \"\\n\")\n",
    "\n",
    "print(\"MODEL        VERSION    COST\")\n",
    "print(\"-----------------------------------\")\n",
    "print(\"Ada\" + \"\\t\\t\" + \"v1\" + \"\\t$\" + '%.8s' % str(ada_v1_embeddings_cost))\n",
    "print(\"Babbage\" + \"\\t\\t\" + \"v1\" + \"\\t$\" + '%.8s' % str(babbage_v1_embeddings_cost))\n",
    "print(\"Curie\" + \"\\t\\t\" + \"v1\" + \"\\t$\" + '%.8s' % str(curie_v1_embeddings_cost))\n",
    "print(\"Davinci\" + \"\\t\\t\" + \"v1\" + \"\\t$\" + '%.8s' % str(davinci_v1_embeddings_cost))\n",
    "print(\"Ada\" + \"\\t\\t\" + \"v2\" + \"\\t$\" + '%.8s' %str(ada_v2_embeddings_cost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "258a9094-98bf-4d47-84a8-ff57ac7f590e",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "556b1d9c-e904-42d3-9584-dbf9733db562",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df.n_tokens<3500]\n",
    "\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a8b721-aaeb-4c7a-a3d0-5edd27a48275",
   "metadata": {},
   "source": [
    "# OpenAI Text & Embedding Rate Limits?\n",
    "\n",
    "Rate limits are enforced at the **organization level, not user level**, based on the specific endpoint used as well as the type of account you have. \n",
    "\n",
    "Rate limits are measured in two ways: **RPM (requests per minute)** and **TPM (tokens per minute)**. \n",
    "\n",
    "## TEXT & EMBEDDING\n",
    "\n",
    "Free trial users •20 RPM •150,000 TPM\n",
    "\n",
    "Pay-as-you-go users (first 48 hours)\t•60 RPM •250,000 TPM\n",
    "\n",
    "Pay-as-you-go users (after 48 hours)\t•3,000 RPM •250,000 TPM\n",
    "\n",
    "https://beta.openai.com/docs/guides/rate-limits/overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c918c32-d166-4ad2-9d81-9c3240f0dd0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from IPython.display import clear_output\n",
    "\n",
    "request_counter = 0\n",
    "total_requests_sent = 0\n",
    "rate_limit= 60\n",
    "\n",
    "def generate_embeddings(text, model=\"text-embedding-ada-002\"):\n",
    "    global request_counter\n",
    "    global rate_limit\n",
    "    global total_requests_sent  \n",
    "    clear_output(wait=True)\n",
    "    \n",
    "    if text==\"\":\n",
    "        text = \"blank\"\n",
    "        print(\"Blank content field detected\")\n",
    "    if request_counter < rate_limit:\n",
    "        request_counter+=1\n",
    "        total_requests_sent+=1\n",
    "        print(\"Request counter: \", request_counter)\n",
    "        print(\"Total requests sent: \", total_requests_sent)\n",
    "    if request_counter == rate_limit:\n",
    "        print(\"Sleeping for 60 seconds\")\n",
    "        time.sleep(60)\n",
    "        request_counter = 0\n",
    "        \n",
    "    return openai.Embedding.create(input = [text], model=model)['data'][0]['embedding']\n",
    " \n",
    "df['ada_v2_embedding'] = df.CONTENT.apply(lambda x: generate_embeddings(x, model='text-embedding-ada-002'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e892a12-c62b-4746-98b9-00642ad20c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4468ce5-fe77-4e67-8f23-1fac4e285e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# search embedded docs based on cosine similarity\n",
    "\n",
    "def get_embedding(text, model=\"text-embedding-ada-002\"):\n",
    "   return openai.Embedding.create(input = [text], model=model)['data'][0]['embedding']\n",
    "\n",
    "def search_docs(df, user_query, top_n=3, to_print=True):\n",
    "    embedding = get_embedding(\n",
    "        user_query,\n",
    "        model=\"text-embedding-ada-002\"\n",
    "    )\n",
    "    df[\"similarities\"] = df.ada_v2_embedding.apply(lambda x: cosine_similarity(x, embedding))\n",
    "\n",
    "    res = (\n",
    "        df.sort_values(\"similarities\", ascending=False)\n",
    "        .head(top_n)\n",
    "    )\n",
    "    if to_print:\n",
    "        display(res)\n",
    "    return res\n",
    "\n",
    "question = input(\"How can I help you?\\n\\n\")\n",
    "\n",
    "res = search_docs(df, question, top_n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "438e5363-b22e-4564-8c21-bd388d3fae8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "res.CONTENT.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bdac244-b3ba-4b1c-a8cd-5215e49d3a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_docs(df, user_query, top_n=3, to_print=True):\n",
    "    embedding = get_embedding(\n",
    "        user_query,\n",
    "        model=\"text-embedding-ada-002\"\n",
    "    )\n",
    "    df[\"similarities\"] = df.ada_v2_embedding.apply(lambda x: cosine_similarity(x, embedding))\n",
    "\n",
    "    res = (\n",
    "        df.sort_values(\"similarities\", ascending=False)\n",
    "        .head(top_n)\n",
    "    )\n",
    "    return res\n",
    "\n",
    "res = search_docs(df, question, top_n=1)\n",
    "\n",
    "ai_question = input(\"How can I help you?\\n\\n\")\n",
    "context= res.CONTENT.values\n",
    "completion_model='text-davinci-003'\n",
    "\n",
    "initial_prompt = \"The following is a conversation with an AI assistant. The assistant is helpful, creative, clever, and very friendly.\"\n",
    "\n",
    "combined_prompt = initial_prompt + str(context) + \"Q: \" + ai_question\n",
    "response = openai.Completion.create(model=completion_model, prompt=combined_prompt, max_tokens=100)\n",
    "ai_response = response['choices'][0]['text'].replace('\\n', '').replace(' .', '.').strip()\n",
    "\n",
    "print(\"\\n\"+ ai_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b0cc12b-8926-4b77-82ea-5fc18ebcf008",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
